{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow        as tf\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from data_process        import *\n",
    "from neuralNetwork       import NeuralNetworkSeparation\n",
    "from Model               import *\n",
    "from sklearn.manifold    import TSNE\n",
    "\n",
    "NUM_SPEAKER    = 77\n",
    "BATCH_START    = 0\n",
    "BATCH_SIZE     = 50\n",
    "TIME_STEP      = 20 # for ntm\n",
    "LR             = 0.0001 # for ntm\n",
    "EPOCH_UP       = 50\n",
    "EPOCH_LOW      = 20\n",
    "SPEAKERIDX     = 0\n",
    "INPUT_SIZE     = 513\n",
    "OUTPUT_SIZE    = 513\n",
    "Mem_size       = 32\n",
    "ARCHITECTURE   = {'l0':{'type':'input', 'neurons':INPUT_SIZE}, \n",
    "                  'l1':{'type':'fc', 'neurons':1000}, \n",
    "                  'l2':{'type':'lstm', 'neurons':1000, 'mem_size':Mem_size}, \n",
    "                  'l3':{'type':'ntm', 'neurons':700, 'mem_size':Mem_size}, \n",
    "                  'l4':{'type':'fc', 'neurons':1000}, \n",
    "                  'l5':{'type':'output', 'neurons':OUTPUT_SIZE}}\n",
    "TOTAL_SIZE     = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "mix_train, target1, target2, sequence_length = get_data_train(\n",
    "    './Train/Mix/', './Train/Target1/', './Train/Target2/', NUM_SPEAKER, BATCH_SIZE, TIME_STEP, longest=200)\n",
    "end = time.time()\n",
    "print'Get data done!', \"    time: \", end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Model(ARCHITECTURE, INPUT_SIZE, OUTPUT_SIZE, BATCH_SIZE, TIME_STEP, LR, activation_function=tf.nn.relu, batch_norm=True)\n",
    "init  = tf.global_variables_initializer()\n",
    "sess  = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MSE = [np.inf] #np.zeros(EPOCH_UP)\n",
    "total_cost = 0\n",
    "for ep in range(EPOCH_UP):\n",
    "    # Training\n",
    "    sp_list = [i for i in range(NUM_SPEAKER)]\n",
    "    random.shuffle(sp_list)    \n",
    "    sp_idx = 0\n",
    "    BATCH_idx = 0 # to record starting point of batch we want to extract\n",
    "    TIME_idx  = 0\n",
    "    start = time.time()\n",
    "    while True:\n",
    "        mix, t1, t2, sequence, sp_idx, BATCH_idx, TIME_idx = get_batch_train(\n",
    "            mix_train, target1, target2, BATCH_idx, TIME_idx, sp_idx, BATCH_SIZE, TIME_STEP, INPUT_SIZE, sp_list, \n",
    "            sequence_length, longest=200)     \n",
    "        \n",
    "        # break\n",
    "        if sp_idx == NUM_SPEAKER:\n",
    "            break\n",
    "        \n",
    "        feed_dict = {\n",
    "                model.x  : mix,\n",
    "                model.y1 : t1,\n",
    "                model.y2 : t2\n",
    "            }\n",
    "        \n",
    "        model.sequence_length = sequence\n",
    "        # stochastic gradient descent\n",
    "        _, cost = sess.run(\n",
    "            [model.train_op, model.cost],\n",
    "            feed_dict\n",
    "            )\n",
    "        if math.isnan(cost):\n",
    "            break\n",
    "        model.init_state_assign()\n",
    "        \n",
    "        # cost\n",
    "        total_cost = total_cost + cost\n",
    "    end = time.time()  \n",
    "    train_time = end-start\n",
    "    \n",
    "    TOTAL_SIZE = 0\n",
    "    for key in sequence_length.keys():\n",
    "        TOTAL_SIZE += sum(sequence_length[key])\n",
    "        \n",
    "    MSE.append(total_cost/(TOTAL_SIZE))\n",
    "    total_cost = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    print 'Epoch: ', ep, ' Training Loss: ', MSE[-1], ' Training Time: ', train_time\n",
    "     \n",
    "    if MSE[-2] - MSE[-1] < 0 and ep > 20: #or ep_idx >= 3:\n",
    "        break\n",
    "    #if ep >= EPOCH_LOW and MSE[ep-1]-MSE[ep] < 0.001:\n",
    "    #    MSE = MSE[0:ep+1]\n",
    "    #    break;    \n",
    "        \n",
    "                        \n",
    "print('----------End----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.plot(MSE)\n",
    "plt.ion()\n",
    "plt.show()\n",
    "\n",
    "for idx in MSE:\n",
    "    print idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Seen speaker test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NUM_SPEAKER_TEST = 6\n",
    "mix_test1, t1_test1, t2_test1, order, sequence_length = get_data_test('./Test1/Mix/', './Test1/Target1/', './Test1/Target2/', \n",
    "                                                                      NUM_SPEAKER_TEST, BATCH_SIZE, TIME_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "total_cost  = 0\n",
    "TOTAL_SIZE  = 0\n",
    "total_pred1 = np.zeros((1, 513))\n",
    "total_pred2 = np.zeros((1, 513))\n",
    "sp_list     = mix_test1.keys()\n",
    "sp_list.sort()\n",
    "for speaker in range(NUM_SPEAKER_TEST):\n",
    "    BATCH_START = 0 # to record starting point of batch we want to extract\n",
    "    DATA_SIZE   = mix_test1[sp_list[speaker]].shape[0]\n",
    "    TOTAL_SIZE  = TOTAL_SIZE + DATA_SIZE\n",
    "    for idx in range((DATA_SIZE/(BATCH_SIZE*TIME_STEP))):\n",
    "        BATCH_START = idx*BATCH_SIZE*TIME_STEP\n",
    "        mix, t1, t2 = get_batch_test(\n",
    "            mix_test1[sp_list[speaker]], t1_test1[sp_list[speaker]], t2_test1[sp_list[speaker]], \n",
    "            BATCH_START, BATCH_SIZE, TIME_STEP, INPUT_SIZE, dim=True)\n",
    "        \n",
    "        feed_dict = {\n",
    "                model.x  : mix,\n",
    "                model.y1 : t1,\n",
    "                model.y2 : t2\n",
    "            }\n",
    "        if idx==(DATA_SIZE/(BATCH_SIZE*TIME_STEP))-1:\n",
    "            model.sequence_length = sequence_length[sp_list[speaker]]\n",
    "            # stochastic gradient descent\n",
    "            cost, pred1, pred2 = sess.run(\n",
    "                [model.cost, model.pred1, model.pred2],\n",
    "                feed_dict\n",
    "                )\n",
    "            model.init_state_assign()\n",
    "            model.sequence_length = [TIME_STEP for i in xrange(0, BATCH_SIZE)]\n",
    "        else:\n",
    "            # stochastic gradient descent\n",
    "            cost, pred1, pred2 = sess.run(\n",
    "                [model.cost, model.pred1, model.pred2],\n",
    "                feed_dict\n",
    "                )\n",
    "            model.init_state_assign()\n",
    "        \n",
    "        total_pred1 = np.append(total_pred1, pred1, axis=0)\n",
    "        total_pred2 = np.append(total_pred2, pred2, axis=0)\n",
    "        # cost\n",
    "        total_cost = total_cost + cost\n",
    "            \n",
    "total_cost = total_cost/(TOTAL_SIZE)\n",
    "print 'The cost of model: ', total_cost\n",
    "MSE = np.concatenate((MSE, [total_cost]), axis=0)\n",
    "total_pred1 = total_pred1[1:, :]\n",
    "total_pred2 = total_pred2[1:, :]\n",
    "total_pred1 = np.transpose(total_pred1)\n",
    "total_pred2 = np.transpose(total_pred2)\n",
    "            \n",
    "print('----------End----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('./Prediction1/Test1/NTM'+'_mem_'+str(Mem_size)+\"_sp_\"+str(NUM_SPEAKER)+'.csv', total_pred1, delimiter=\",\")\n",
    "np.savetxt('./Prediction2/Test1/NTM'+'_mem_'+str(Mem_size)+\"_sp_\"+str(NUM_SPEAKER)+'.csv', total_pred2, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Unseen speaker test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NUM_SPEAKER_TEST = 6\n",
    "mix_test2, t1_test2, t2_test2, order, sequence_length = get_data_test('./Test2/Mix/', './Test2/Target1/', './Test2/Target2/', \n",
    "                                                                      NUM_SPEAKER_TEST, BATCH_SIZE, TIME_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "total_cost  = 0\n",
    "TOTAL_SIZE  = 0\n",
    "total_pred1 = np.zeros((1, 513))\n",
    "total_pred2 = np.zeros((1, 513))\n",
    "sp_list     = mix_test2.keys()\n",
    "sp_list.sort()\n",
    "for speaker in range(NUM_SPEAKER_TEST):\n",
    "    BATCH_START = 0 # to record starting point of batch we want to extract\n",
    "    DATA_SIZE   = mix_test2[sp_list[speaker]].shape[0]\n",
    "    TOTAL_SIZE  = TOTAL_SIZE + DATA_SIZE\n",
    "    for idx in range((DATA_SIZE/(BATCH_SIZE*TIME_STEP))):\n",
    "        BATCH_START = idx*BATCH_SIZE*TIME_STEP\n",
    "        mix, t1, t2 = get_batch_test(\n",
    "            mix_test2[sp_list[speaker]], t1_test2[sp_list[speaker]], t2_test2[sp_list[speaker]], \n",
    "            BATCH_START, BATCH_SIZE, TIME_STEP, INPUT_SIZE, dim=True)\n",
    "        \n",
    "        feed_dict = {\n",
    "                model.x  : mix,\n",
    "                model.y1 : t1,\n",
    "                model.y2 : t2\n",
    "            }\n",
    "        \n",
    "        if idx==(DATA_SIZE/(BATCH_SIZE*TIME_STEP))-1:\n",
    "            model.sequence_length = sequence_length[sp_list[speaker]]\n",
    "            # stochastic gradient descent\n",
    "            cost, pred1, pred2 = sess.run(\n",
    "                [model.cost, model.pred1, model.pred2],\n",
    "                feed_dict\n",
    "                )\n",
    "            model.init_state_assign()\n",
    "            model.sequence_length = [TIME_STEP for i in xrange(0, BATCH_SIZE)]\n",
    "        else:\n",
    "            # stochastic gradient descent\n",
    "            cost, pred1, pred2 = sess.run(\n",
    "                [model.cost, model.pred1, model.pred2],\n",
    "                feed_dict\n",
    "                )\n",
    "            model.init_state_assign()\n",
    "        \n",
    "        total_pred1 = np.append(total_pred1, pred1, axis=0)\n",
    "        total_pred2 = np.append(total_pred2, pred2, axis=0)\n",
    "        # cost\n",
    "        total_cost = total_cost + cost\n",
    "            \n",
    "total_cost = total_cost/(TOTAL_SIZE)\n",
    "print 'The cost of model: ', total_cost\n",
    "MSE = np.concatenate((MSE, [total_cost]), axis=0)\n",
    "total_pred1 = total_pred1[1:, :]\n",
    "total_pred2 = total_pred2[1:, :]\n",
    "total_pred1 = np.transpose(total_pred1)\n",
    "total_pred2 = np.transpose(total_pred2)\n",
    "            \n",
    "print('----------End----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('./Prediction1/Test2/NTM'+'_mem_'+str(Mem_size)+\"_sp_\"+str(NUM_SPEAKER)+'.csv', total_pred1, delimiter=\",\")\n",
    "np.savetxt('./Prediction2/Test2/NTM'+'_mem_'+str(Mem_size)+\"_sp_\"+str(NUM_SPEAKER)+'.csv', total_pred2, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
